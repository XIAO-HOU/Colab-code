{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test.ipynb",
      "provenance": [],
      "mount_file_id": "1N0BP_9UijErqLHFlDTkQPfTr-TSNGYgI",
      "authorship_tag": "ABX9TyMSi+5jx9bzvQTHr2nZ9CHa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XIAO-HOU/Colab-code/blob/main/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7g-kqOpFePw"
      },
      "source": [
        "import torch\n",
        "import math\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from collections import defaultdict\n",
        "from torch import nn\n",
        "\n",
        "cora_path = 'drive/MyDrive/Colab Notebooks/data/cora'"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czzcSWJML1ct"
      },
      "source": [
        "def load_data(source):\n",
        "  content_path = source + '/cora.content'\n",
        "  cite_path = source + '/cora.cites'\n",
        "\n",
        "  features = []\n",
        "  labels = []\n",
        "  node_map = {}\n",
        "  label_map = {}\n",
        "\n",
        "  with open(content_path) as f:\n",
        "    for i, line in enumerate(f):\n",
        "      info = line.strip().split()\n",
        "      features.append([float(x) for x in info[1:-1]])\n",
        "      node_map[info[0]] = i\n",
        "      if info[-1] not in label_map:\n",
        "        label_map[info[-1]] = len(label_map)\n",
        "      labels.append(label_map[info[-1]])\n",
        "  features = np.asarray(features)\n",
        "  labels = np.asarray(labels)\n",
        "\n",
        "  adj_list = defaultdict(set)\n",
        "  adj_matrix = np.zeros((features.shape[0], features.shape[0]))\n",
        "  with open(cite_path) as f:\n",
        "    for i, line in enumerate(f):\n",
        "      info = line.strip().split()\n",
        "      assert len(info) == 2\n",
        "      paper1 = node_map[info[0]]\n",
        "      paper2 = node_map[info[1]]\n",
        "      adj_list[paper1].add(paper2)\n",
        "      adj_matrix[paper1][paper2] = 1\n",
        "      adj_list[paper2].add(paper1)\n",
        "      adj_matrix[paper2][paper1] = 1\n",
        "  \n",
        "  return features, labels, adj_list, adj_matrix\n",
        "\n",
        "features, labels, adj_list, adj_matrix = load_data(cora_path)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xw1RM2auRmyN",
        "outputId": "6a3c7808-68c4-4393-ea76-42ca8184cb5f"
      },
      "source": [
        "adj_matrix"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usjzI1YpGBwq"
      },
      "source": [
        "class GCN(nn.Module):\n",
        "  def __init__(self, nfeat, nhid, nclass, dropout):\n",
        "      super(GCN, self).__init__()\n",
        "\n",
        "      self.gc1 = GraphConvolution(nfeat, nhid)\n",
        "      self.gc2 = GraphConvolution(nhid, nclass)\n",
        "      self.dropout = dropout\n",
        "\n",
        "  def forward(self, x, adj):\n",
        "      x = F.relu(self.gc1(x, adj))\n",
        "      x = F.dropout(x, self.dropout, training=self.training)\n",
        "      x = self.gc2(x, adj)\n",
        "      return F.log_softmax(x, dim=1)\n",
        "\n",
        "class GraphConvolution(nn.Module):\n",
        "  def __init__(self, in_features, out_features, bias = True):\n",
        "    super(GraphConvolution, self).__init__()\n",
        "    self.in_features = in_features\n",
        "    self.out_features = out_features\n",
        "    self.weight = nn.Parameter(torch.FloatTensor(in_features, out_features))\n",
        "    if bias:\n",
        "      self.bias = nn.Parameter(torch.FloatTensor(out_features))\n",
        "    else:\n",
        "      self.register_parameter('bias', None)\n",
        "    self.reset_parameters()\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    stdv = 1. / math.sqrt(self.weight.size(1))\n",
        "    self.weight.data.uniform_(-stdv, stdv)\n",
        "    if self.bias is not None:\n",
        "        self.bias.data.uniform_(-stdv, stdv)\n",
        "\n",
        "  def forward(self, input, adj):\n",
        "      support = torch.mm(input, self.weight)\n",
        "      output = torch.mm(adj, support)\n",
        "      if self.bias is not None:\n",
        "          return output + self.bias\n",
        "      else:\n",
        "          return output"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVsfanK0KyYf"
      },
      "source": [
        "def normalize(mx):\n",
        "  row_sum = np.array(mx.sum(1))\n",
        "  r_inv = np.power(row_sum, -0.5).flatten()\n",
        "  r_inv[np.isinf(r_inv)] = 0.\n",
        "  r_mat_inv = np.diag(r_inv)\n",
        "  mx = r_mat_inv.dot(mx).dot(r_mat_inv)\n",
        "  return mx\n",
        "\n",
        "def accuracy(output, labels):\n",
        "  preds = output.max(1)[1].type_as(labels)\n",
        "  correct = preds.eq(labels).double()\n",
        "  correct = correct.sum()\n",
        "  return correct / len(labels)\n",
        "\n",
        "def split_data(nodes_num, test_split=3, val_split=6):\n",
        "  rand_indices = np.random.permutation(nodes_num)\n",
        "\n",
        "  test_size = nodes_num // test_split\n",
        "  val_size = nodes_num // val_split\n",
        "  # train_size = nodes_num - test_size - val_size\n",
        "\n",
        "  test_indexes = rand_indices[:test_size]\n",
        "  val_indexes = rand_indices[test_size:(test_size + val_size)]\n",
        "  train_indexes = rand_indices[test_size + val_size:]\n",
        "\n",
        "  return train_indexes, val_indexes, test_indexes"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VWij9V6IyfN"
      },
      "source": [
        "features = torch.Tensor(features)\n",
        "labels = torch.LongTensor(labels)\n",
        "adj_matrix = normalize(adj_matrix + np.eye(adj_matrix.shape[0]))\n",
        "adj_matrix = torch.Tensor(adj_matrix)\n",
        "train_indexes, val_indexes, test_indexes = split_data(features.shape[0])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgXeLQ0ySU7G"
      },
      "source": [
        "hidden = 16\n",
        "dropout = 0.5\n",
        "lr = 0.01\n",
        "weight_decay = 5e-4\n",
        "\n",
        "model = GCN(nfeat=features.shape[1],\n",
        "        nhid=hidden,\n",
        "        nclass=labels.max().item() + 1,\n",
        "        dropout=dropout)\n",
        "optimizer = optim.Adam(model.parameters(),lr=lr,\n",
        "              weight_decay=weight_decay)\n",
        "\n",
        "def train(epoch):\n",
        "  t = time.time()\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "  output = model(features, adj_matrix)\n",
        "  loss_train = F.nll_loss(output[train_indexes], labels[train_indexes])\n",
        "  acc_train = accuracy(output[train_indexes], labels[train_indexes])\n",
        "  loss_train.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  model.eval()\n",
        "  output = model(features, adj_matrix)\n",
        "\n",
        "  loss_val = F.nll_loss(output[val_indexes], labels[val_indexes])\n",
        "  acc_val = accuracy(output[val_indexes], labels[val_indexes])\n",
        "  print('Epoch: {:04d}'.format(epoch+1),\n",
        "      'loss_train: {:.4f}'.format(loss_train.item()),\n",
        "      'acc_train: {:.4f}'.format(acc_train.item()),\n",
        "      'loss_val: {:.4f}'.format(loss_val.item()),\n",
        "      'acc_val: {:.4f}'.format(acc_val.item()),\n",
        "      'time: {:.4f}s'.format(time.time() - t))\n",
        "\n",
        "\n",
        "def test():\n",
        "  model.eval()\n",
        "  output = model(features, adj_matrix)\n",
        "  loss_test = F.nll_loss(output[test_indexes], labels[test_indexes])\n",
        "  acc_test = accuracy(output[test_indexes], labels[test_indexes])\n",
        "  print('Test set results:',\n",
        "      'loss={:.4f}'.format(loss_test.item()),\n",
        "      'accuracy={:.4f}'.format(acc_test.item()))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "px0Kdrw4WwWv"
      },
      "source": [
        "epochs = 200\n",
        "start_time = time.time()\n",
        "for epoch in range(epochs):\n",
        "    train(epoch)\n",
        "print(\"Optimization Finished!\")\n",
        "print(\"Total time elapsed: {:.4f}s\".format(time.time() - start_time))\n",
        "\n",
        "test()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}